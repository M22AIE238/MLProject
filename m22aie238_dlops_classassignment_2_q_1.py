# -*- coding: utf-8 -*-
"""M22AIE238_DLOps_ClassAssignment_2_Q_1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14a8xCGlyJLw4VFiIww6ieYC3dIGrAf1Z
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from torch.utils.tensorboard import SummaryWriter
from sklearn.metrics import precision_score, recall_score, precision_recall_curve, average_precision_score
import numpy as np

# MLP with Different Hidden Layers
class MLP2(nn.Module):
    def __init__(self):
        super(MLP2, self).__init__()
        self.fc1 = nn.Linear(784, 512)  # Reduced hidden layer size
        self.fc2 = nn.Linear(512, 256)  # Additional hidden layer
        self.fc3 = nn.Linear(256, 10)

    def forward(self, x):
        x = x.view(x.size(0), -1)
        x = torch.relu(self.fc1(x))
        x = torch.relu(self.fc2(x))
        x = self.fc3(x)
        return x

# Define a sequence of transformations
data_transforms = transforms.Compose([
    transforms.Resize((28, 28)),  # Adjust image size
    transforms.ToTensor(),        # Convert images to tensors
    transforms.Normalize((0.5,), (0.5,))  # Normalize images
])

usps_train_dataset = datasets.USPS(root='./data', train=True, transform=data_transforms, download=True)
usps_test_dataset = datasets.USPS(root='./data', train=False, transform=data_transforms, download=True)

train_loader = DataLoader(usps_train_dataset, batch_size=64, shuffle=True)
test_loader = DataLoader(usps_test_dataset, batch_size=64, shuffle=False)

from torch import optim, nn
import torch
from sklearn.metrics import precision_score, recall_score, precision_recall_curve
from torch.utils.tensorboard import SummaryWriter

# Initialize the model, loss function, and optimizer
neural_net = MLP()
loss_function = nn.CrossEntropyLoss()
adam_optimizer = optim.Adam(neural_net.parameters(), lr=0.001)

# Set the number of training epochs
epochs = 10
log_writer = SummaryWriter()

# Begin the training process
for epoch_num in range(epochs):
    for batch_index, (inputs, labels) in enumerate(train_loader):
        adam_optimizer.zero_grad()
        predictions = neural_net(inputs)
        loss = loss_function(predictions, labels)
        loss.backward()
        adam_optimizer.step()

        # Determine the max predictions
        _, preds = torch.max(predictions.data, 1)

        # Log loss
        log_writer.add_scalar('Training Loss', loss.item(), epoch_num)

        # Convert predictions and labels to numpy arrays for metrics calculations
        preds_np = preds.cpu().numpy()
        labels_np = labels.cpu().numpy()

        # Calculate precision and recall
        prec = precision_score(labels_np, preds_np, average='macro')
        rec = recall_score(labels_np, preds_np, average='macro')

        # Log precision and recall
        log_writer.add_scalar('Training Precision', prec, epoch_num)
        log_writer.add_scalar('Training Recall', rec, epoch_num)

        # Precision and recall for each class
        prec_per_class = {}
        rec_per_class = {}
        for class_index in range(10):
            prec_per_class[class_index], rec_per_class[class_index], _ = precision_recall_curve(labels_np == class_index, preds_np == class_index)
            log_writer.add_pr_curve(f'Class {class_index} PR Curve', prec_per_class[class_index], rec_per_class[class_index], epoch_num)

log_writer.close()

# Commented out IPython magic to ensure Python compatibility.
# %load_ext tensorboard
# %tensorboard --logdir=runs

"""## Training the CNN"""

class CNN(nn.Module):
    def __init__(self):
        super(CNN, self).__init__()
        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)
        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)
        self.fc1 = nn.Linear(3136, 10)

    def forward(self, x):
        x = torch.relu(self.conv1(x))
        x = torch.max_pool2d(x, 2)
        x = torch.relu(self.conv2(x))
        x = torch.max_pool2d(x, 2)
        x = x.view(x.size(0), -1)
        x = self.fc1(x)
        return x

from torch import nn, optim
import torch
from sklearn.metrics import precision_score, recall_score, precision_recall_curve
from torch.utils.tensorboard import SummaryWriter

# Initialize the convolutional neural network, loss function, and optimizer
conv_net = CNN()
loss_evaluator = nn.CrossEntropyLoss()
adam_optimizer = optim.Adam(conv_net.parameters(), lr=0.001)

# Specify the number of epochs for training
total_epochs = 10
tensorboard_writer = SummaryWriter()

# Execute the training cycle
for current_epoch in range(total_epochs):
    for batch_num, (images, labels) in enumerate(train_loader):
        adam_optimizer.zero_grad()
        prediction = conv_net(images)
        training_loss = loss_evaluator(prediction, labels)
        training_loss.backward()
        adam_optimizer.step()

        # Determine the predicted classes
        _, pred_labels = torch.max(prediction.data, 1)

        # Log the training loss
        tensorboard_writer.add_scalar('Training/Loss', training_loss.item(), current_epoch)

        # Convert tensors to numpy arrays for calculating precision and recall
        pred_labels_np = pred_labels.cpu().numpy()
        labels_np = labels.cpu().numpy()

        # Compute precision and recall
        calculated_precision = precision_score(labels_np, pred_labels_np, average='macro')
        calculated_recall = recall_score(labels_np, pred_labels_np, average='macro')

        # Log precision and recall
        tensorboard_writer.add_scalar('Training/Precision', calculated_precision, current_epoch)
        tensorboard_writer.add_scalar('Training/Recall', calculated_recall, current_epoch)

        # Log precision-recall curve for each class
        for class_idx in range(10):
            class_precision, class_recall, _ = precision_recall_curve(labels_np == class_idx, pred_labels_np == class_idx)
            tensorboard_writer.add_pr_curve(f'Class_{class_idx}/Precision-Recall', class_precision, class_recall, current_epoch)

tensorboard_writer.close()

# Commented out IPython magic to ensure Python compatibility.
# %load_ext tensorboard
# %tensorboard --logdir=runs